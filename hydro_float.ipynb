{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m\n\u001b[0;32m     24\u001b[0m             pixel_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Flatten pixel values into a 1D array\u001b[39;00m\n\u001b[0;32m     26\u001b[0m             \u001b[38;5;66;03m# Append data to the list\u001b[39;00m\n\u001b[0;32m     27\u001b[0m             data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     28\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m: split,\n\u001b[0;32m     29\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: label,\n\u001b[1;32m---> 30\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: val \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pixel_values)}\n\u001b[0;32m     31\u001b[0m             })\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Convert the list of data to a DataFrame\u001b[39;00m\n\u001b[0;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Paths to dataset folders\n",
    "base_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat-Dataset\\images'\n",
    "folders = ['train', 'test', 'val']  # The three splits\n",
    "\n",
    "# Initialize an empty list to hold data\n",
    "data = []\n",
    "\n",
    "# Process each folder\n",
    "for split in folders:\n",
    "    folder_path = os.path.join(base_path, split)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(('jpg', 'png', 'jpeg')):  # Ensure it's an image file\n",
    "            # Extract label from the file name\n",
    "            label = file_name.split('-')[0]  # Assuming label is before the first underscore\n",
    "            \n",
    "            # Load the image and convert to pixel values\n",
    "            image_path = os.path.join(folder_path, file_name)\n",
    "            image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "            pixel_values = np.array(image).flatten()  # Flatten pixel values into a 1D array\n",
    "            \n",
    "            # Append data to the list\n",
    "            data.append({\n",
    "                'split': split,\n",
    "                'label': label,\n",
    "                **{f'pixel_{i}': val for i, val in enumerate(pixel_values)}\n",
    "            })\n",
    "\n",
    "# Convert the list of data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_path = 'HydroFloat_dataset.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"CSV file created successfully at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully at: E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "#Memory error solved\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Paths to dataset folders\n",
    "base_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat-Dataset\\images'\n",
    "folders = ['train', 'test', 'val']  # The three splits\n",
    "\n",
    "# Output CSV file\n",
    "output_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset.csv'\n",
    "\n",
    "# Initialize the CSV file and write headers\n",
    "with open(output_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['split', 'label'] + [f'pixel_{i}' for i in range(3 * 224 * 224)])  # Adjust resolution if necessary\n",
    "\n",
    "# Process each folder\n",
    "    for split in folders:\n",
    "        folder_path = os.path.join(base_path, split)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(('jpg', 'png', 'jpeg')):  # Ensure it's an image file\n",
    "                # Extract label from the file name\n",
    "                label = file_name.rsplit('-', 1)[0]  # Get the part before the last hyphen\n",
    "\n",
    "                # Load the image, resize, and flatten pixel values\n",
    "                image_path = os.path.join(folder_path, file_name)\n",
    "                image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "                image = image.resize((224, 224))  # Resize to a smaller resolution\n",
    "                pixel_values = np.array(image).flatten()  # Flatten pixel values into a 1D array\n",
    "\n",
    "                # Write a row to the CSV file\n",
    "                writer.writerow([split, label] + pixel_values.tolist())\n",
    "\n",
    "print(f\"CSV file created successfully at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized CSV file created successfully at: E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_optimized.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Paths to dataset folders\n",
    "base_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat-Dataset\\images'\n",
    "folders = ['train', 'test', 'val']  # The three splits\n",
    "\n",
    "# Output CSV file\n",
    "output_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_optimized.csv'\n",
    "\n",
    "# Image resolution for resizing\n",
    "resize_resolution = (64, 64)  # Reduce resolution to 64x64\n",
    "\n",
    "# Initialize the CSV file and write headers\n",
    "with open(output_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    writer.writerow(['split', 'label'] + [f'pixel_{i}' for i in range(3 * resize_resolution[0] * resize_resolution[1])])  # Adjust resolution\n",
    "\n",
    "# Process each folder\n",
    "    for split in folders:\n",
    "        folder_path = os.path.join(base_path, split)\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(('jpg', 'png', 'jpeg')):  # Ensure it's an image file\n",
    "                # Extract label from the file name\n",
    "                label = file_name.rsplit('-', 1)[0]  # Get the part before the last hyphen\n",
    "\n",
    "                # Load the image, resize, normalize, and flatten pixel values\n",
    "                image_path = os.path.join(folder_path, file_name)\n",
    "                image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "                image = image.resize(resize_resolution)  # Resize to smaller resolution\n",
    "                pixel_values = (np.array(image) / 255.0).flatten().astype(np.float32)  # Normalize to 0-1\n",
    "\n",
    "                # Write a row to the CSV file\n",
    "                writer.writerow([split, label] + pixel_values.tolist())\n",
    "\n",
    "print(f\"Optimized CSV file created successfully at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file saved at: E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input and output file paths\n",
    "input_csv_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_optimized.csv'\n",
    "output_csv_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_updated.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Function to clean and update labels\n",
    "def clean_label(label):\n",
    "    # Remove unwanted characters or numbers\n",
    "    label = ''.join(filter(str.isalpha, label))  # Keep only alphabetic characters\n",
    "    \n",
    "    # Replace specific patterns\n",
    "    label = label.replace('v', 'garbage patch')  # Replace 'v' with 'garbage patch'\n",
    "    label = label.replace('bb', 'plastic bottles')  # Replace 'bb' with 'plastic bottles'\n",
    "    label = label.replace('ylg', 'container')  # Replace 'ylg' with 'container'\n",
    "    label = label.replace('.jpg', '')  # Remove '.jpg' from the label\n",
    "    \n",
    "    return label\n",
    "\n",
    "# Apply the cleaning function to the label column\n",
    "df['label'] = df['label'].apply(clean_label)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Updated CSV file saved at: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final updated CSV file saved at: E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_final.csv\n"
     ]
    }
   ],
   "source": [
    "#Final label update\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Input and output file paths\n",
    "input_csv_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_updated.csv'\n",
    "output_csv_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_final.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Function to clean the labels further\n",
    "def refine_label(label):\n",
    "    # Remove 'jpg' at the end, if present\n",
    "    if label.endswith('jpg'):\n",
    "        label = label[:-3]\n",
    "    \n",
    "    # Remove 'a' at the beginning, if present\n",
    "    if label.startswith('A'):\n",
    "        label = label[1:]\n",
    "    \n",
    "    return label.strip()  # Remove any extra spaces\n",
    "\n",
    "# Apply the refinement function to the label column\n",
    "df['label'] = df['label'].apply(refine_label)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Final updated CSV file saved at: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for null values...\n",
      "split          0\n",
      "label          0\n",
      "pixel_0        0\n",
      "pixel_1        0\n",
      "pixel_2        0\n",
      "              ..\n",
      "pixel_12283    0\n",
      "pixel_12284    0\n",
      "pixel_12285    0\n",
      "pixel_12286    0\n",
      "pixel_12287    0\n",
      "Length: 12290, dtype: int64\n",
      "Checking for duplicate rows...\n",
      "Number of duplicate rows: 3\n",
      "Removing duplicate rows...\n",
      "Checking for unexpected values in 'split' and 'label' columns...\n",
      "Unique values in 'split': ['train' 'test' 'val']\n",
      "Unique values in 'label': ['bag' 'deadfish' 'xdeadfish' 'xinbag' 'plastic bottles' 'fish'\n",
      " 'garbage patch' 'waterhyacinth' 'container']\n",
      "Checking pixel values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sushmita Aich\\AppData\\Local\\Temp\\ipykernel_2280\\1567348412.py:47: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  non_numeric_pixels = df[pixel_columns].applymap(lambda x: not isinstance(x, (int, float))).sum().sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric pixel values: 0\n",
      "Preprocessed dataset saved at: E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "#Pre-processed dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_final.csv'  # Update with the path to your dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 1. Check for null values\n",
    "print(\"Checking for null values...\")\n",
    "null_counts = df.isnull().sum()\n",
    "print(null_counts)\n",
    "\n",
    "# Handle null values\n",
    "if null_counts.any():\n",
    "    print(\"Handling null values...\")\n",
    "    # Option 1: Drop rows with null values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Option 2: Fill null values (uncomment if needed)\n",
    "    # df['split'] = df['split'].fillna('unknown')  # Replace with default value for 'split'\n",
    "    # df['label'] = df['label'].fillna('unknown')  # Replace with default value for 'label'\n",
    "    # df.iloc[:, 2:] = df.iloc[:, 2:].fillna(0)  # Fill missing pixel values with 0\n",
    "\n",
    "# 2. Check for duplicate rows\n",
    "print(\"Checking for duplicate rows...\")\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "# Remove duplicate rows if any\n",
    "if duplicate_count > 0:\n",
    "    print(\"Removing duplicate rows...\")\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "# 3. Check for inconsistent or unexpected values in 'split' and 'label'\n",
    "print(\"Checking for unexpected values in 'split' and 'label' columns...\")\n",
    "print(\"Unique values in 'split':\", df['split'].unique())\n",
    "print(\"Unique values in 'label':\", df['label'].unique())\n",
    "\n",
    "# 4. Normalize 'split' column (Optional: standardize split names)\n",
    "valid_splits = ['train', 'test', 'val']\n",
    "df = df[df['split'].isin(valid_splits)]  # Remove rows with invalid 'split' values\n",
    "\n",
    "# 5. Pixel value checks (ensure all are numeric)\n",
    "print(\"Checking pixel values...\")\n",
    "pixel_columns = df.columns[2:]  # All pixel columns\n",
    "non_numeric_pixels = df[pixel_columns].applymap(lambda x: not isinstance(x, (int, float))).sum().sum()\n",
    "print(f\"Non-numeric pixel values: {non_numeric_pixels}\")\n",
    "\n",
    "# Convert all pixel values to numeric, coercing errors to NaN\n",
    "df[pixel_columns] = df[pixel_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle any resulting NaN pixel values (if coercion introduced NaN values)\n",
    "df[pixel_columns] = df[pixel_columns].fillna(0)\n",
    "\n",
    "# 6. Save the cleaned and preprocessed dataset\n",
    "output_file_path = r'E:\\3rd Year NOTES\\A.I. & M.L\\HYDRO_FLOAT\\HydroFloat_dataset_preprocessed.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"Preprocessed dataset saved at: {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
